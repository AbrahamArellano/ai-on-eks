apiVersion: batch/v1
kind: Job
metadata:
  name: lora-finetune-app
spec:
  backoffLimit: 2
  ttlSecondsAfterFinished: 86400
  template:
    spec:
      containers:
        - name: app
          image: <account-id>.dkr.ecr.<region>.amazonaws.com/llm-finetune/llama-finetuning-trn:feature-lora
          command: ['/bin/bash', '-c']
          args:
            - |-
              TIMESTAMP=$(date +%Y%m%d-%H%M%S); \
              MODEL_OUTPUT_DIR="/shared/llama3_tuned_model_$TIMESTAMP"; \
              /scripts/llama3_finetuning.sh "$MODEL_OUTPUT_DIR" > /shared/llama3_finetuning_"$TIMESTAMP".out 2>&1
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: huggingface-secret
                  key: HF_TOKEN
          volumeMounts:
            - name: persistent-storage
              mountPath: /shared
            - name: dshm
              mountPath: /dev/shm
            - name: script-volume
              mountPath: /scripts
          resources:
            limits:
              aws.amazon.com/neuron: '16'
            requests:
              aws.amazon.com/neuron: '16'
      volumes:
        - name: persistent-storage
          persistentVolumeClaim:
            claimName: fsx-static-pvc
        - name: dshm
          emptyDir:
            medium: Memory
        - name: script-volume
          configMap:
            name: llama3-finetuning-script
            defaultMode: 0755
      restartPolicy: Never
      nodeSelector:
        type: karpenter
        instanceType: trainium-trn1
      tolerations:
        - key: 'aws.amazon.com/neuron'
          value: 'true'
          effect: 'NoSchedule'
