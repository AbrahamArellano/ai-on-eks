apiVersion: v1
kind: Secret
metadata:
  name: huggingface-secret
type: Opaque
data:
  HF_TOKEN: ${HUGGINGFACE_HUB_ACCESS_TOKEN}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: lora-finetune-app
spec:
  backoffLimit: 2
  ttlSecondsAfterFinished: 86400
  template:
    spec:
      containers:
        - name: app
          image: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training-neuronx:2.1.2-transformers4.43.2-neuronx-py310-sdk2.20.0-ubuntu20.04
          imagePullPolicy: Always
          command: ["/bin/bash", "-c"]
          args: ["/scripts/llama3_finetuning.sh > /shared/llama3_finetuning.out 2>&1"]
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: huggingface-secret
                  key: HF_TOKEN
          volumeMounts:
            - name: persistent-storage
              mountPath: /shared
            - name: dshm
              mountPath: /dev/shm
            - name: script-volume
              mountPath: /scripts
          resources:
            limits:
              aws.amazon.com/neuron: '16'
            requests:
              aws.amazon.com/neuron: '16'
      volumes:
        - name: persistent-storage
          persistentVolumeClaim:
            claimName: fsx-static-pvc
        - name: dshm
          emptyDir:
            medium: Memory
        - name: script-volume
          configMap:
            name: llama3-finetuning-script
            defaultMode: 0755
      restartPolicy: Never
      nodeSelector:
        type: karpenter
        instanceType: trainium-trn1
      tolerations:
        - key: 'aws.amazon.com/neuron'
          value: 'true'
          effect: 'NoSchedule'
