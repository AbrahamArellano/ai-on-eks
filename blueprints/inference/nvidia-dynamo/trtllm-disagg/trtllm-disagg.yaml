# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: trtllm-disagg
spec:
  services:
    Frontend:
      dynamoNamespace: trtllm-disagg
      componentType: main
      replicas: 1
      livenessProbe:
        exec:
          command:
            - /bin/sh
            - -c
            - 'curl -s http://localhost:8000/health | jq -e ".status == \"healthy\""'
        periodSeconds: 5
        timeoutSeconds: 3
        failureThreshold: 3
      readinessProbe:
        exec:
          command:
            - /bin/sh
            - -c
            - 'curl -s http://localhost:8000/health | jq -e ".status == \"healthy\""'
        initialDelaySeconds: 60
        periodSeconds: 60
        timeoutSeconds: 3
        failureThreshold: 10
      resources:
        requests:
          cpu: "2"
          memory: "4Gi"
        limits:
          cpu: "2"
          memory: "4Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/trtllm-runtime:0.4.0
          workingDir: /workspace/components/backends/trtllm
          command:
            - /bin/sh
            - -c
          args:
            - "python3 -m dynamo.frontend --http-port 8000"
    TRTLLMDecodeWorker:
      dynamoNamespace: trtllm-disagg
      envFromSecret: hf-token-secret
      componentType: worker
      replicas: 2
      livenessProbe:
        httpGet:
          path: /live
          port: 9090
        periodSeconds: 5
        timeoutSeconds: 3
        failureThreshold: 3
      readinessProbe:
        httpGet:
          path: /health
          port: 9090
        periodSeconds: 10
        timeoutSeconds: 3
        failureThreshold: 120  # TensorRT compilation can take time
      resources:
        requests:
          cpu: "8"
          memory: "20Gi"
          gpu: "1"
        limits:
          cpu: "8"
          memory: "20Gi"
          gpu: "1"
      envs:
        - name: DYN_SYSTEM_ENABLED
          value: "true"
        - name: DYN_SYSTEM_USE_ENDPOINT_HEALTH_STATUS
          value: "[\"generate\"]"
        - name: DYN_SYSTEM_PORT
          value: "9090"
      extraPodSpec:
        nodeSelector:
          karpenter.sh/nodepool: g5-gpu-karpenter
        mainContainer:
          startupProbe:
            httpGet:
              path: /health
              port: 9090
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 120  # Allow extra time for TensorRT compilation
          image: nvcr.io/nvidia/ai-dynamo/trtllm-runtime:0.4.0
          workingDir: /workspace/components/backends/trtllm
          args:
            - "python3"
            - "-m"
            - "dynamo.trtllm"
            - "--model-path"
            - "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            - "--served-model-name"
            - "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            - "--extra-engine-args"
            - "engine_configs/decode.yaml"
            - "--disaggregation-mode"
            - "decode"
    TRTLLMPrefillWorker:
      dynamoNamespace: trtllm-disagg
      envFromSecret: hf-token-secret
      componentType: worker
      replicas: 1
      livenessProbe:
        httpGet:
          path: /live
          port: 9090
        periodSeconds: 5
        timeoutSeconds: 3
        failureThreshold: 3
      readinessProbe:
        httpGet:
          path: /health
          port: 9090
        periodSeconds: 10
        timeoutSeconds: 3
        failureThreshold: 120  # TensorRT compilation can take time
      resources:
        requests:
          cpu: "8"
          memory: "20Gi"
          gpu: "1"
        limits:
          cpu: "8"
          memory: "20Gi"
          gpu: "1"
      envs:
        - name: DYN_SYSTEM_ENABLED
          value: "true"
        - name: DYN_SYSTEM_USE_ENDPOINT_HEALTH_STATUS
          value: "[\"generate\"]"
        - name: DYN_SYSTEM_PORT
          value: "9090"
      extraPodSpec:
        nodeSelector:
          karpenter.sh/nodepool: g5-gpu-karpenter
        mainContainer:
          startupProbe:
            httpGet:
              path: /health
              port: 9090
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 120  # Allow extra time for TensorRT compilation
          image: nvcr.io/nvidia/ai-dynamo/trtllm-runtime:0.4.0
          workingDir: /workspace/components/backends/trtllm
          args:
            - "python3"
            - "-m"
            - "dynamo.trtllm"
            - "--model-path"
            - "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            - "--served-model-name"
            - "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
            - "--extra-engine-args"
            - "engine_configs/prefill.yaml"
            - "--disaggregation-mode"
            - "prefill"
