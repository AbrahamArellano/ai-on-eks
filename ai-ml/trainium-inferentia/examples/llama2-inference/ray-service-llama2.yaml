---
apiVersion: v1
kind: Namespace
metadata:
  name: llama2

---
apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: llama2-service
  namespace: llama2
spec:
  serviceUnhealthySecondThreshold: 900
  deploymentUnhealthySecondThreshold: 300
  serveConfig:
    importPath: ray_serve_llama2:entrypoint  # Specify the correct path to your Python script
    runtimeEnv: |
      env_vars: {"MODEL_ID": "NousResearch/Llama-2-13b-chat-hf"}  # Replace with the appropriate model ID

  rayClusterConfig:
    rayVersion: '2.7.1'
    headGroupSpec:
      serviceType: ClusterIP
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
            - name: ray-head
              image: public.ecr.aws/data-on-eks/ray-serve-inf2-llama2:latest
              lifecycle:
                preStop:
                  exec:
                    command: [ "/bin/sh","-c","ray stop" ]
              ports:
                - containerPort: 6379
                  name: gcs
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
              volumeMounts:
                - mountPath: /tmp/ray
                  name: ray-logs
              resources:
                limits:
                  cpu: 2
                  memory: 8Gi
                requests:
                  cpu: 2
                  memory: 8Gi
          nodeSelector:
            provisioner: default
            workload: rayhead
          volumes:
            - name: ray-logs
              emptyDir: {}

    workerGroupSpecs:
      - groupName: inf2-worker-group
        replicas: 1
        minReplicas: 1
        maxReplicas: 1
        rayStartParams: {}
        template:
          spec:
            containers:
              - name: ray-worker
                image: public.ecr.aws/data-on-eks/ray-serve-inf2-llama2:latest
                lifecycle:
                  preStop:
                    exec:
                      command: [ "/bin/sh","-c","ray stop" ]
                resources:
                  limits:
                    cpu: "90"
                    memory: "300G"
                    aws.amazon.com/neuron: "6"
                  requests:
                    cpu: "90"
                    memory: "300G"
                    aws.amazon.com/neuron: "6"
            nodeSelector:
              karpenter.sh/provisioner-name: inferentia-inf2
              hub.jupyter.org/node-purpose: user
            tolerations:
              - key: aws.amazon.com/neuroncore
                operator: Exists
                effect: NoSchedule
              - key: aws.amazon.com/neuron
                operator: Exists
                effect: NoSchedule
              - key: "hub.jupyter.org/dedicated"
                operator: "Equal"
                value: "user"
                effect: "NoSchedule"
